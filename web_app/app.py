import os
import sys
import logging
import traceback

logging.basicConfig(
    level=logging.DEBUG, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

os.environ["CUDA_VISIBLE_DEVICES"] = ""
os.environ["FORCE_CUDA"] = "0"

import streamlit as st
import torch
import numpy as np
from PIL import Image
import io
import json
import pandas as pd
import gdown
from pathlib import Path
import subprocess
import shutil

st.set_page_config(
    page_title="StyleGAN-NADA Generator",
    page_icon="üé®",
    layout="wide",
    initial_sidebar_state="expanded",
)

page = st.sidebar.selectbox(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª", ["üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è", "üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏", "üìã –û—Ç—á–µ—Ç"]
)

BEST_MODELS = {
    "anime_style": {
        "model_key": "anime_style_freeze_2",
        "name": "–ê–Ω–∏–º–µ-—Å—Ç–∏–ª—å",
        "cos_sim": 0.1851,
    },
    "sketch_style": {
        "model_key": "sketch_style_freeze_0",
        "name": "–°–∫–µ—Ç—á-—Å—Ç–∏–ª—å",
        "cos_sim": 0.1675,
    },
    "joker_style": {
        "model_key": "joker_style_freeze_2",
        "name": "–°—Ç–∏–ª—å –î–∂–æ–∫–µ—Ä–∞",
        "cos_sim": 0.2241,
    },
    "oil_painting_style": {
        "model_key": "oil_painting_style_freeze_2",
        "name": "–ö–∞—Ä—Ç–∏–Ω–∞ –º–∞—Å–ª–æ–º",
        "cos_sim": 0.2085,
    },
}


@st.cache_resource
def download_stylegan_nada():
    stylegan_nada_dir = Path("stylegan_nada")

    if stylegan_nada_dir.exists() and (stylegan_nada_dir / "ZSSGAN").exists():
        return str(stylegan_nada_dir)

    with st.spinner("–ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è stylegan-nada –∏–∑ GitHub..."):
        try:
            result = subprocess.run(
                ["git", "--version"], capture_output=True, text=True
            )
            if result.returncode != 0:
                st.error(
                    "Git –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω! –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Git –¥–ª—è –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è."
                )
                return None

            if stylegan_nada_dir.exists():
                shutil.rmtree(stylegan_nada_dir)

            result = subprocess.run(
                [
                    "git",
                    "clone",
                    "https://github.com/rinongal/stylegan-nada.git",
                    str(stylegan_nada_dir),
                ],
                capture_output=True,
                text=True,
                timeout=300,
            )

            if result.returncode == 0 and (stylegan_nada_dir / "ZSSGAN").exists():
                return str(stylegan_nada_dir)
            else:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è: {result.stderr}")
                return None

        except subprocess.TimeoutExpired:
            st.error("–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
            return None
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è: {e}")
            return None


@st.cache_resource
def download_base_model():
    models_dir = Path("models")
    models_dir.mkdir(exist_ok=True)

    model_path = models_dir / "ffhq.pt"

    if model_path.exists():
        return str(model_path)

    with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ FFHQ –∏–∑ –æ–±–ª–∞–∫–∞..."):
        try:
            gdown.download(
                "https://drive.google.com/uc?id=1EM87UquaoQmk17Q8d5kYIAHqu0dkYqdT",
                str(model_path),
                quiet=True,
            )
            if model_path.exists():
                return str(model_path)
            else:
                st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å")
                return None
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {e}")
            return None


@st.cache_resource
def load_models():
    device = "cpu"

    base_model_path = download_base_model()
    if not base_model_path:
        return None

    stylegan_nada_dir = download_stylegan_nada()
    if not stylegan_nada_dir:
        return None

    if device == "cpu":
        try:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.dirname(current_dir)
            setup_script = os.path.join(project_root, "setup_cpu_support.py")

            if not os.path.exists(setup_script):
                setup_script = os.path.join(os.getcwd(), "setup_cpu_support.py")

            if os.path.exists(setup_script):
                sys.path.insert(0, os.path.dirname(setup_script))
                from setup_cpu_support import setup_cpu_support

                setup_cpu_support(stylegan_nada_dir)
            else:
                st.warning(
                    f"–°–∫—Ä–∏–ø—Ç setup_cpu_support.py –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–∫–∞–ª–∏: {setup_script}"
                )
                st.info(
                    "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–∫—Ä–∏–ø—Ç –≤—Ä—É—á–Ω—É—é: python setup_cpu_support.py"
                )
        except Exception as e:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å CPU-–ø–æ–¥–¥–µ—Ä–∂–∫—É: {e}")
            import traceback

            st.code(traceback.format_exc())

    sys.path.append(stylegan_nada_dir)
    sys.path.append(os.path.join(stylegan_nada_dir, "ZSSGAN"))

    try:
        from ZSSGAN.model.ZSSGAN import SG2Generator
    except ImportError as e:
        st.error(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ ZSSGAN: {e}")
        st.info("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π stylegan-nada –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ")
        return None

    try:
        base_checkpoint = torch.load(base_model_path, map_location="cpu")
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {e}")
        import traceback

        with st.expander("üîç –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏"):
            st.code(traceback.format_exc())
        return None

    models = {}
    models_dir = "models"

    for style_key, style_info in BEST_MODELS.items():
        model_key = style_info["model_key"]
        model_file = f"final_model_{model_key}.pt"
        model_path = os.path.join(models_dir, model_file)

        if not os.path.exists(model_path):
            st.warning(f"–ú–æ–¥–µ–ª—å {model_key} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –ø—É—Ç–∏: {model_path}")
            continue

        try:
            checkpoint = torch.load(model_path, map_location="cpu")
            metadata = checkpoint.get("metadata", {})

            generator_wrapper = SG2Generator(
                base_model_path, img_size=1024, device=device
            )

            if hasattr(generator_wrapper, "generator"):
                generator_wrapper.generator = generator_wrapper.generator.to(device)
                for name, param in generator_wrapper.generator.named_parameters():
                    if param.device.type != "cpu":
                        st.warning(
                            f"‚ö†Ô∏è {style_key}: –ü–∞—Ä–∞–º–µ—Ç—Ä {name} –±–∞–∑–æ–≤–æ–≥–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –Ω–µ –Ω–∞ CPU: {param.device}"
                        )
                        generator_wrapper.generator = generator_wrapper.generator.to(
                            device
                        )
                        break

            if "generator_state_dict" in checkpoint:
                state_dict = checkpoint["generator_state_dict"]
                new_state_dict = {}
                for key, value in state_dict.items():
                    if key.startswith("generator."):
                        new_key = key[len("generator.") :]
                        new_state_dict[new_key] = value
                    else:
                        new_state_dict[key] = value

                missing_keys, unexpected_keys = (
                    generator_wrapper.generator.load_state_dict(
                        new_state_dict, strict=False
                    )
                )

                if missing_keys:
                    st.warning(
                        f"‚ö†Ô∏è {style_key}: –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–ª—é—á–∏ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ ({len(missing_keys)}): {list(missing_keys)[:5]}..."
                    )
                if unexpected_keys:
                    st.warning(
                        f"‚ö†Ô∏è {style_key}: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ –∫–ª—é—á–∏ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ ({len(unexpected_keys)}): {list(unexpected_keys)[:5]}..."
                    )

            generator_wrapper.eval()

            if hasattr(generator_wrapper, "generator"):
                generator_wrapper.generator = generator_wrapper.generator.to(device)
                generator_wrapper.generator.eval()

                cpu_params = 0
                non_cpu_params = 0
                for name, param in generator_wrapper.generator.named_parameters():
                    if param.device.type == "cpu":
                        cpu_params += 1
                    else:
                        non_cpu_params += 1
                        st.warning(
                            f"‚ö†Ô∏è {style_key}: –ü–∞—Ä–∞–º–µ—Ç—Ä {name} –Ω–µ –Ω–∞ CPU: {param.device}"
                        )
                        param.data = param.data.to(device)

                for name, buffer in generator_wrapper.generator.named_buffers():
                    if buffer.device.type != "cpu":
                        st.warning(
                            f"‚ö†Ô∏è {style_key}: –ë—É—Ñ–µ—Ä {name} –Ω–µ –Ω–∞ CPU: {buffer.device}"
                        )
                        buffer.data = buffer.data.to(device)

                if non_cpu_params > 0:
                    st.warning(
                        f"‚ö†Ô∏è {style_key}: –ù–∞–π–¥–µ–Ω–æ {non_cpu_params} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–µ –Ω–∞ CPU, –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ"
                    )

            models[style_key] = {
                "generator": generator_wrapper,
                "name": style_info["name"],
                "model_key": model_key,
                "cos_sim": style_info["cos_sim"],
                "metadata": metadata,
            }


        except Exception as e:
            st.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {model_key}: {e}")
            import traceback

            with st.expander(f"üîç –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ {model_key}"):
                st.code(traceback.format_exc())

    if not models:
        st.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π!")
        return None

    return models


def tensor_to_pil(tensor):
    try:
        if tensor.dim() == 4:
            tensor = tensor[0]
        elif tensor.dim() == 2:
            tensor = tensor.unsqueeze(0).repeat(3, 1, 1)
        elif tensor.dim() != 3:
            raise ValueError(
                f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Ç–µ–Ω–∑–æ—Ä–∞: {tensor.dim()}, —Ñ–æ—Ä–º–∞: {tensor.shape}"
            )

        if tensor.device.type != "cpu":
            tensor = tensor.cpu()

        if tensor.dim() != 3:
            raise ValueError(
                f"–ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–Ω–∑–æ—Ä –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 3D, –ø–æ–ª—É—á–µ–Ω–æ: {tensor.dim()}, —Ñ–æ—Ä–º–∞: {tensor.shape}"
            )

        if tensor.shape[0] > 3:
            tensor = tensor[:3]
        elif tensor.shape[0] == 1:
            tensor = tensor.repeat(3, 1, 1)
        elif tensor.shape[0] != 3:
            raise ValueError(
                f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤: {tensor.shape[0]}, —Ñ–æ—Ä–º–∞: {tensor.shape}"
            )

        if tensor.shape[0] != 3:
            raise ValueError(
                f"–ü–µ—Ä–µ–¥ permute –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 3 –∫–∞–Ω–∞–ª–∞, –ø–æ–ª—É—á–µ–Ω–æ: {tensor.shape[0]}, —Ñ–æ—Ä–º–∞: {tensor.shape}"
            )

        img_np = (
            ((tensor.permute(1, 2, 0).numpy() + 1) / 2 * 255)
            .clip(0, 255)
            .astype(np.uint8)
        )

        if img_np.shape[2] != 3:
            raise ValueError(
                f"–ü–æ—Å–ª–µ permute –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 3 –∫–∞–Ω–∞–ª–∞, –ø–æ–ª—É—á–µ–Ω–æ: {img_np.shape[2]}, —Ñ–æ—Ä–º–∞: {img_np.shape}"
            )

        return Image.fromarray(img_np)
    except Exception as e:
        error_info = f"–û—à–∏–±–∫–∞ –≤ tensor_to_pil:\n"
        error_info += f"  –ò—Å—Ö–æ–¥–Ω–∞—è —Ñ–æ—Ä–º–∞ —Ç–µ–Ω–∑–æ—Ä–∞: {tensor.shape if hasattr(tensor, 'shape') else 'N/A'}\n"
        error_info += (
            f"  –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {tensor.dim() if hasattr(tensor, 'dim') else 'N/A'}\n"
        )
        error_info += (
            f"  –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {tensor.device if hasattr(tensor, 'device') else 'N/A'}\n"
        )
        error_info += f"  –¢–∏–ø: {type(tensor)}\n"
        error_info += f"  –û—à–∏–±–∫–∞: {str(e)}"
        raise ValueError(error_info) from e


if page == "üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è":
    st.title("üé® StyleGAN-NADA Generator")
    st.markdown("### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ç–∏–ª—è—Ö")

    with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π..."):
        models = load_models()

    if not models:
        st.error("‚ùå –ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
        st.stop()

    with st.sidebar:
        st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")

        st.subheader("üé® –í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–∏–ª—å:")
        style_options = {info["name"]: key for key, info in models.items()}
        selected_style_name = st.selectbox("–°—Ç–∏–ª—å:", list(style_options.keys()))
        selected_style_key = style_options[selected_style_name]

        selected_model = models[selected_style_key]
        st.info(f"**–ú–æ–¥–µ–ª—å:** {selected_model['name']}")
        st.info(f"**–ö–∞—á–µ—Å—Ç–≤–æ:** Cosine similarity: {selected_model['cos_sim']:.4f}")

        st.subheader("üé≤ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:")

        seed_mode = st.radio("–†–µ–∂–∏–º seed:", ["üé≤ –°–ª—É—á–∞–π–Ω—ã–π", "üî¢ –ó–∞–¥–∞—Ç—å —Å–≤–æ–π"])

        if seed_mode == "üé≤ –°–ª—É—á–∞–π–Ω—ã–π":
            if st.button("üé≤ –ù–æ–≤—ã–π —Å–ª—É—á–∞–π–Ω—ã–π seed"):
                import random

                seed = random.randint(0, 1000000)
                st.session_state.seed = seed
            else:
                seed = st.session_state.get("seed", 42)
        else:
            seed = st.number_input(
                "Seed:",
                value=st.session_state.get("seed", 42),
                min_value=0,
                max_value=1000000,
                step=1,
            )
            st.session_state.seed = seed

    col1, col2 = st.columns([2, 1])

    with col1:
        if st.button("üé® –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å!", type="primary", width="stretch"):
            with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π..."):
                try:
                    generator = selected_model["generator"]
                    device = "cpu"

                    if hasattr(generator, "generator"):
                        generator.generator = generator.generator.to(device)
                        generator.generator.eval()

                    if hasattr(generator, "generator") and hasattr(
                        generator.generator, "synthesis"
                    ):
                        first_param = next(generator.generator.synthesis.parameters())
                        if first_param.device.type != "cpu":
                            st.warning(
                                f"‚ö†Ô∏è –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –Ω–µ –Ω–∞ CPU! –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {first_param.device}"
                            )
                            generator.generator = generator.generator.to(device)

                    torch.manual_seed(seed)

                    with torch.no_grad():
                        try:
                            z = torch.randn(1, 512, device=device)

                            truncation = 0.8
                            truncation_latent = None
                            if hasattr(generator, "mean_latent"):
                                if isinstance(
                                    generator.mean_latent, torch.Tensor
                                ):
                                    truncation_latent = (
                                        generator.mean_latent.to(device)
                                    )
                                else:
                                    truncation_latent = generator.mean_latent(
                                        n_latent=2048
                                    ).to(device)
                            else:
                                w_avg_samples = []
                                for _ in range(100):
                                    z_sample = torch.randn(
                                        1, 512, device=device
                                    )
                                    if hasattr(generator, "generator"):
                                        w_sample = generator.generator.style(
                                            z_sample
                                        )
                                    else:
                                        w_sample = generator.style(z_sample)
                                    w_avg_samples.append(w_sample)
                                truncation_latent = torch.cat(
                                    w_avg_samples, dim=0
                                ).mean(dim=0, keepdim=True)

                            if z.device.type != "cpu":
                                z = z.cpu()
                            if (
                                truncation_latent is not None
                                and truncation_latent.device.type != "cpu"
                            ):
                                truncation_latent = truncation_latent.cpu()

                            if hasattr(generator, "generator"):
                                for param in generator.generator.parameters():
                                    if param.device.type != "cpu":
                                        st.warning(
                                            f"‚ö†Ô∏è –ü–∞—Ä–∞–º–µ—Ç—Ä –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –Ω–µ –Ω–∞ CPU: {param.device}"
                                        )
                                        break

                            try:
                                logger.debug(
                                    f"–í—ã–∑–æ–≤ generator() –¥–ª—è —Å—Ç–∏–ª—è {selected_model['name']}"
                                )
                                logger.debug(f"z shape: {z.shape}, z device: {z.device}, z dtype: {z.dtype}")
                                if truncation_latent is not None:
                                    logger.debug(f"truncation_latent shape: {truncation_latent.shape}, device: {truncation_latent.device}, dtype: {truncation_latent.dtype}")
                                
                                try:
                                    image, _ = generator(
                                        [z],
                                        truncation=truncation,
                                        truncation_latent=truncation_latent,
                                    )
                                    logger.debug("Generator –≤—ã–∑–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
                                except RuntimeError as rt_error:
                                    error_tb = traceback.format_exc()
                                    logger.error(f"RuntimeError –ø—Ä–∏ –≤—ã–∑–æ–≤–µ generator(): {rt_error}\n{error_tb}")
                                    raise
                                except Exception as inner_error:
                                    error_tb = traceback.format_exc()
                                    logger.error(f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ generator(): {inner_error}\n{error_tb}")
                                    raise
                                
                                if image is None:
                                    raise ValueError("–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–µ—Ä–Ω—É–ª None")
                                
                                logger.debug(f"Generator –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç, —Ç–∏–ø: {type(image)}")
                                
                                if isinstance(image, (list, tuple)):
                                    if len(image) == 0:
                                        raise ValueError("–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫")
                                    img_tensor = image[0]
                                    logger.debug(f"–ò–∑–≤–ª–µ—á–µ–Ω img_tensor –∏–∑ —Å–ø–∏—Å–∫–∞, —Ñ–æ—Ä–º–∞: {img_tensor.shape if hasattr(img_tensor, 'shape') else 'N/A'}")
                                elif isinstance(image, torch.Tensor):
                                    img_tensor = image
                                    logger.debug(f"–ò–∑–≤–ª–µ—á–µ–Ω img_tensor –Ω–∞–ø—Ä—è–º—É—é, —Ñ–æ—Ä–º–∞: {img_tensor.shape}")
                                else:
                                    raise TypeError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞: {type(image)}")
                                
                                if not isinstance(img_tensor, torch.Tensor):
                                    raise TypeError(f"–û–∂–∏–¥–∞–ª—Å—è torch.Tensor, –ø–æ–ª—É—á–µ–Ω {type(img_tensor)}")
                                
                                if img_tensor.device.type != "cpu":
                                    logger.debug(f"–ü–µ—Ä–µ–º–µ—â–∞–µ–º img_tensor —Å {img_tensor.device} –Ω–∞ CPU")
                                    img_tensor = img_tensor.cpu()

                                logger.debug(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ä–º—ã —Ç–µ–Ω–∑–æ—Ä–∞: dim={img_tensor.dim()}, shape={img_tensor.shape}")
                                
                                if img_tensor.dim() == 4:
                                    if img_tensor.shape[0] > 1:
                                        logger.debug(f"–ë–∞—Ç—á –∏–∑ {img_tensor.shape[0]} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –±–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ")
                                    img_tensor = img_tensor[0]  # [C, H, W]
                                    logger.debug(f"–ü–æ—Å–ª–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–∑ –±–∞—Ç—á–∞: shape={img_tensor.shape}")
                                elif img_tensor.dim() != 3:
                                    error_msg = f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Ç–µ–Ω–∑–æ—Ä–∞: {img_tensor.dim()}, —Ñ–æ—Ä–º–∞: {img_tensor.shape}"
                                    logger.error(error_msg)
                                    raise ValueError(error_msg)
                                
                                logger.debug(f"–§–∏–Ω–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞ –ø–µ—Ä–µ–¥ tensor_to_pil: {img_tensor.shape}")
                                
                                img_pil = tensor_to_pil(img_tensor)
                                st.image(
                                    img_pil,
                                    caption=f"–°—Ç–∏–ª—å: {selected_model['name']} | Seed: {seed}",
                                    width="stretch",
                                )

                                buf = io.BytesIO()
                                img_pil.save(buf, format="PNG")
                                st.download_button(
                                    label="üì• –°–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
                                    data=buf.getvalue(),
                                    file_name=f"{selected_style_key}_seed{seed}.png",
                                    mime="image/png",
                                    width="stretch",
                                )
                                
                            except Exception as call_error:
                                error_tb = traceback.format_exc()
                                logger.error(
                                    f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ generator() –¥–ª—è —Å—Ç–∏–ª—è '{selected_model['name']}': {call_error}\n{error_tb}"
                                )
                                st.error(
                                    f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ generator() –¥–ª—è —Å—Ç–∏–ª—è '{selected_model['name']}': {call_error}"
                                )

                                st.text("–ü–æ–ª–Ω—ã–π traceback:")
                                st.code(error_tb)
                                with st.expander(
                                    f"üîç –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏ –≤—ã–∑–æ–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞"
                                ):
                                    st.code(error_tb)
                                raise
                        except Exception as gen_error:
                            st.error(
                                f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —Å—Ç–∏–ª—è '{selected_model['name']}': {gen_error}"
                            )
                            import traceback

                            with st.expander(
                                f"üîç –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
                            ):
                                st.code(traceback.format_exc())
                            raise

                except Exception as e:
                    error_msg = str(e)
                    error_tb = traceback.format_exc()

                    st.error(
                        f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —Å—Ç–∏–ª—è '{selected_model['name']}': {error_msg}"
                    )

                    st.text("–ü–æ–ª–Ω—ã–π traceback –æ—à–∏–±–∫–∏:")
                    st.code(error_tb)

                    if "cuda" in error_msg.lower() or "device" in error_msg.lower():
                        st.warning(
                            "üí° –ü–æ—Ö–æ–∂–µ –Ω–∞ –ø—Ä–æ–±–ª–µ–º—É —Å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ–º. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ CPU."
                        )
                    elif "tensor" in error_msg.lower() or "shape" in error_msg.lower():
                        st.warning(
                            "üí° –ü–æ—Ö–æ–∂–µ –Ω–∞ –ø—Ä–æ–±–ª–µ–º—É —Å —Ñ–æ—Ä–º–æ–π —Ç–µ–Ω–∑–æ—Ä–∞ –∏–ª–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ–º."
                        )
                    elif "dtype" in error_msg.lower() or "float" in error_msg.lower():
                        st.warning(
                            "üí° –ü–æ—Ö–æ–∂–µ –Ω–∞ –ø—Ä–æ–±–ª–µ–º—É —Å —Ç–∏–ø–æ–º –¥–∞–Ω–Ω—ã—Ö (dtype). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å float32."
                        )

                    with st.expander(
                        f"üîç –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏ (—Å—Ç–∏–ª—å: {selected_model['name']})"
                    ):
                        st.code(error_tb)

                    st.info(
                        "üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏–ª–∏ –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥–æ–π —Å—Ç–∏–ª—å."
                    )

    with col2:
        st.info(f"**–°—Ç–∏–ª—å:** {selected_model['name']}")
        st.info(f"**–ö–∞—á–µ—Å—Ç–≤–æ:** {selected_model['cos_sim']:.4f}")

        metadata = selected_model.get("metadata", {})
        if metadata:
            target_class = metadata.get("target_class", "N/A")
            st.info(f"**–ü—Ä–æ–º–ø—Ç:** {target_class[:60]}...")

        st.info(f"**Seed:** {seed}")

elif page == "üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏":
    st.title("üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è")

    output_dir = "output"
    visualizations_dir = os.path.join(output_dir, "visualizations")

    if not os.path.exists(visualizations_dir):
        st.warning("–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        st.info("–ó–∞–ø—É—Å—Ç–∏—Ç–µ –Ω–æ—É—Ç–±—É–∫ train_and_save.ipynb –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π")
    else:
        st.header("üìà –ì—Ä–∞—Ñ–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π")

        col1, col2 = st.columns(2)

        with col1:
            quality_by_style = os.path.join(visualizations_dir, "quality_by_style.png")
            if os.path.exists(quality_by_style):
                st.subheader("–ö–∞—á–µ—Å—Ç–≤–æ –ø–æ —Å—Ç–∏–ª—è–º")
                st.image(quality_by_style, width="stretch")

            effect_of_freeze = os.path.join(visualizations_dir, "effect_of_freeze.png")
            if os.path.exists(effect_of_freeze):
                st.subheader("–í–ª–∏—è–Ω–∏–µ –∑–∞–º–æ—Ä–æ–∑–∫–∏ —Å–ª–æ–µ–≤")
                st.image(effect_of_freeze, width="stretch")

        with col2:
            quality_heatmap = os.path.join(visualizations_dir, "quality_heatmap.png")
            if os.path.exists(quality_heatmap):
                st.subheader("Heatmap –∫–∞—á–µ—Å—Ç–≤–∞")
                st.image(quality_heatmap, width="stretch")

            convergence_best = os.path.join(
                visualizations_dir, "convergence_best_models.png"
            )
            if os.path.exists(convergence_best):
                st.subheader("–°—Ö–æ–¥–∏–º–æ—Å—Ç—å –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π")
                st.image(convergence_best, width="stretch")

        st.header("üé® –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –ø–æ —Å—Ç–∏–ª—è–º")

        comparison_files = {
            "–ê–Ω–∏–º–µ": "comparison_anime_style.png",
            "–î–∂–æ–∫–µ—Ä": "comparison_joker_style.png",
            "–°–∫–µ—Ç—á": "comparison_sketch_style.png",
            "–ö–∞—Ä—Ç–∏–Ω–∞ –º–∞—Å–ª–æ–º": "comparison_oil_painting_style.png",
        }

        cols = st.columns(2)
        for idx, (style_name, filename) in enumerate(comparison_files.items()):
            filepath = os.path.join(visualizations_dir, filename)
            if os.path.exists(filepath):
                with cols[idx % 2]:
                    st.subheader(style_name)
                    st.image(filepath, width="stretch")

        st.header("üìâ –ì—Ä–∞—Ñ–∏–∫–∏ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏")
        convergence_dir = os.path.join(visualizations_dir, "convergence_plots")

        if os.path.exists(convergence_dir):
            convergence_files = [
                f for f in os.listdir(convergence_dir) if f.endswith(".png")
            ]
            if convergence_files:
                cols = st.columns(2)
                for idx, filename in enumerate(convergence_files[:4]):
                    filepath = os.path.join(convergence_dir, filename)
                    with cols[idx % 2]:
                        st.image(filepath, width="stretch", caption=filename)

elif page == "üìã –û—Ç—á–µ—Ç":
    st.title("üìã –û—Ç—á–µ—Ç –æ –ø—Ä–æ–µ–∫—Ç–µ")

    st.header("üìä –ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–µ–π")

    metrics_file = "output/detailed_metrics_all_experiments.json"

    if os.path.exists(metrics_file):
        with open(metrics_file, "r", encoding="utf-8") as f:
            metrics_data = json.load(f)

        st.subheader("–õ—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ —Å—Ç–∏–ª—è–º")

        best_models_table = []
        for style_key, style_info in BEST_MODELS.items():
            best_models_table.append(
                {
                    "–°—Ç–∏–ª—å": style_info["name"],
                    "–ú–æ–¥–µ–ª—å": style_info["model_key"],
                    "Cosine Similarity": f"{style_info['cos_sim']:.4f}",
                }
            )

        df_best = pd.DataFrame(best_models_table)
        st.dataframe(df_best, width="stretch", hide_index=True)

        st.subheader("–°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤")

        models_data = metrics_data.get("models", {})
        if models_data:
            rows = []
            for model_name, model_info in models_data.items():
                if model_info.get("exists"):
                    rows.append(
                        {
                            "–ú–æ–¥–µ–ª—å": model_name,
                            "–°—Ç–∏–ª—å": model_info.get("base_model", "N/A"),
                            "–ó–∞–º–æ—Ä–æ–∂–µ–Ω–æ —Å–ª–æ–µ–≤": model_info.get("freeze_layers", "N/A"),
                            "–§–∏–Ω–∞–ª—å–Ω—ã–π Loss": (
                                f"{model_info.get('final_loss', 0):.4f}"
                                if model_info.get("final_loss")
                                else "N/A"
                            ),
                            "Cosine Similarity": (
                                f"{model_info.get('cos_sim', 0):.4f}"
                                if model_info.get("cos_sim")
                                else "N/A"
                            ),
                            "–†–∞–∑–º–µ—Ä (MB)": (
                                f"{model_info.get('size_mb', 0):.2f}"
                                if model_info.get("size_mb")
                                else "N/A"
                            ),
                        }
                    )

            if rows:
                df = pd.DataFrame(rows)
                st.dataframe(df, width="stretch", hide_index=True)

        st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        stats = metrics_data.get("statistics", {})
        if stats:
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric(
                    "–°—Ä–µ–¥–Ω–∏–π Loss",
                    (
                        f"{stats.get('avg_loss', 0):.4f}"
                        if stats.get("avg_loss")
                        else "N/A"
                    ),
                )
            with col2:
                st.metric(
                    "–°—Ä–µ–¥–Ω–∏–π Cosine Similarity",
                    (
                        f"{stats.get('avg_cos_sim', 0):.4f}"
                        if stats.get("avg_cos_sim")
                        else "N/A"
                    ),
                )
            with col3:
                st.metric(
                    "–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–µ–π (MB)",
                    (
                        f"{stats.get('total_size_mb', 0):.2f}"
                        if stats.get("total_size_mb")
                        else "N/A"
                    ),
                )

        st.subheader("–õ—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ —Å—Ç–∏–ª—è–º")
        best_models = metrics_data.get("summary", {}).get("best_models_by_style", {})
        if best_models:
            for style, info in best_models.items():
                st.write(
                    f"**{style}**: {info.get('model_name', 'N/A')} (cos_sim: {info.get('cos_sim', 0):.4f})"
                )

    else:
        st.warning("–§–∞–π–ª —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        st.info("–ó–∞–ø—É—Å—Ç–∏—Ç–µ –Ω–æ—É—Ç–±—É–∫ train_and_save.ipynb –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫")

    st.header("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–µ–∫—Ç–µ")

    st.markdown(
        """
    ### –û–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ç–æ–¥–∞
    
    **StyleGAN-NADA** (Non-Adversarial Domain Adaptation) ‚Äî –º–µ—Ç–æ–¥ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π 
    –∫ –Ω–æ–≤—ã–º –¥–æ–º–µ–Ω–∞–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π.
    
    ### –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç–∏–ª–∏:
    
    1. **–ê–Ω–∏–º–µ-—Å—Ç–∏–ª—å** - –∞–¥–∞–ø—Ç–∞—Ü–∏—è –≤ —Å—Ç–∏–ª—å —è–ø–æ–Ω—Å–∫–æ–π –∞–Ω–∏–º–∞—Ü–∏–∏
    2. **–°–∫–µ—Ç—á-—Å—Ç–∏–ª—å** - –∏–º–∏—Ç–∞—Ü–∏—è –∫–∞—Ä–∞–Ω–¥–∞—à–Ω–æ–≥–æ —Ä–∏—Å—É–Ω–∫–∞
    3. **–°—Ç–∏–ª—å –î–∂–æ–∫–µ—Ä–∞** - —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–º–∏ —á–µ—Ä—Ç–∞–º–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
    4. **–ö–∞—Ä—Ç–∏–Ω–∞ –º–∞—Å–ª–æ–º** - —ç—Ñ—Ñ–µ–∫—Ç –º–∞—Å–ª—è–Ω–æ–π –∂–∏–≤–æ–ø–∏—Å–∏
    
    ### –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏:
    
    - –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: StyleGAN2 FFHQ (1024√ó1024)
    - CLIP –º–æ–¥–µ–ª–∏: –∞–Ω—Å–∞–º–±–ª—å –∏–∑ ViT-B/32, ViT-B/16, ViT-L/14
    - Learning rate: 0.002
    - –ò—Ç–µ—Ä–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è: 600
    - –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –∑–∞–º–æ—Ä–æ–∑–∫–æ–π —Å–ª–æ–µ–≤: 0, 2, 4
    
    ### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:
    
    –í—Å–µ–≥–æ –æ–±—É—á–µ–Ω–æ **12 –º–æ–¥–µ–ª–µ–π** (4 —Å—Ç–∏–ª—è √ó 3 –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∑–∞–º–æ—Ä–æ–∑–∫–∏).
    –í –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ª—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ –∫–∞–∂–¥–æ–º—É —Å—Ç–∏–ª—é.
    """
    )
